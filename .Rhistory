# Grid Search and Hyperparameter
tempTest = c()
tempTrain = c()
for (i in 1:700) {
rForest = randomForest(myFormula, data = train, importance = TRUE, do.trace = FALSE, ntree = i, mtry = 5, nodesize = (abs(i - 90)))
pred = predict(rForest, test)
pred2 = predict(rForest, train)
print(i)
tempTrain[i] = (sum(pred2 == train$status_group)/nrow(train))
tempTest[i] = (sum(pred == test$status_group)/nrow(test))
print(tempTest[i])
if (tempTest[i] >= 0.82) {
break;
}
}
plot(tempTrain, main = 'Learning Curve - rForest (gSearch 100:500)', type = 'l', col = 'red', xlim = c(99, 501), ylim = c(0.73, 0.83), ylab = 'Accuracy')
lines(tempTest, type = 'l', col = 'blue')
plot(tempTrain, main = 'Learning Curve - rForest (gSearch 1:500)', type = 'l', col = 'red', xlim = c(99, 501), ylim = c(0.73, 0.83), ylab = 'Accuracy')
lines(tempTest, type = 'l', col = 'blue')
legend("topright", inset = 0.15, title = "datasets", c("train","test"), fill = c("red","blue"), horiz = FALSE)
lines(tempTrain - tempTest, type = 'l', col = 'cyan')
plot(tempTrain - tempTest, type = 'l', col = 'cyan')
plot(tempTrain, main = 'Learning Curve - rForest (gSearch 1:500)', type = 'l', col = 'red', xlim = c(99, 501), ylim = c(0.73, 0.83), ylab = 'Accuracy')
lines(tempTest, type = 'l', col = 'blue')
lines(tempTrain - tempTest, type = 'l', col = 'cyan')
legend("topright", inset = 0.15, title = "datasets", c("train","test"), fill = c("red","blue"), horiz = FALSE)
plot(tempTrain - tempTest, type = 'l', col = 'cyan', main = 'Difference between train/test accuracy')
plot(tempTrain - tempTest, type = 'l', col = 'cyan', main = 'Difference between train/test accuracy')
plot(tempTrain - tempTest, type = 'l', col = 'cyan', main = 'Difference between train/test accuracy (gSearch 1:500)')
plot(tempTrain - tempTest, type = 'l', col = 'cyan', main = 'Train Test accuracy (gSearch 1:500)')
plot(tempTrain, main = 'Learning Curve - rForest (gSearch 1:500)', type = 'l', col = 'red', xlim = c(99, 501), ylim = c(0.73, 0.83), ylab = 'Accuracy')
lines(tempTest, type = 'l', col = 'blue')
lines(tempTrain - tempTest, type = 'l', col = 'cyan')
legend("topright", inset = 0.15, title = "datasets", c("train","test"), fill = c("red","blue"), horiz = FALSE)
plot(tempTrain, main = 'Learning Curve - rForest (gSearch 1:500)', type = 'l', col = 'red', ylim = c(0.73, 0.83), ylab = 'Accuracy')
plot(tempTrain, main = 'Learning Curve - rForest (gSearch 1:500)', type = 'l', col = 'red', ylim = c(0.73, 0.83), ylab = 'Accuracy')
plot(tempTrain, main = 'Learning Curve - rForest (gSearch 1:500)', type = 'l', col = 'red', ylim = c(0.73, 0.83), ylab = 'Accuracy')
lines(tempTest, type = 'l', col = 'blue')
lines(tempTrain - tempTest, type = 'l', col = 'cyan')
legend("topright", inset = 0.15, title = "datasets", c("train","test"), fill = c("red","blue"), horiz = FALSE)
plot(tempTrain, main = 'Learning Curve - rForest (gSearch 1:500)', type = 'l', col = 'red', xlim = c(0, 500), ylim = c(0.74, 0.85), ylab = 'Accuracy')
plot(tempTrain, main = 'Learning Curve - rForest (gSearch 1:500)', type = 'l', col = 'red', xlim = c(0, 500), ylim = c(0.74, 0.86), ylab = 'Accuracy')
plot(tempTrain, main = 'Learning Curve - rForest (gSearch 1:500)', type = 'l', col = 'red', xlim = c(0, 500), ylim = c(0.75, 0.86), ylab = 'Accuracy')
lines(tempTest, type = 'l', col = 'blue')
4
plot(tempTrain, main = 'Learning Curve - rForest (gSearch 1:500)', type = 'l', col = 'red', xlim = c(0, 500), ylim = c(0.74, 0.86), ylab = 'Accuracy')
lines(tempTest, type = 'l', col = 'blue')
plot(tempTrain - tempTest, type = 'l', col = 'cyan', main = 'Train Test accuracy (gSearch 1:500)', xlim = c(0, 500))
plot(tempTrain, main = 'Learning Curve - rForest (gSearch 1:500)', type = 'l', col = 'red', xlim = c(0, 500), ylim = c(0.74, 0.86), ylab = 'Accuracy')
lines(tempTest, type = 'l', col = 'blue')
lines(tempTrain - tempTest, type = 'l', col = 'cyan')
plot(tempTrain, main = 'Learning Curve - rForest (gSearch 1:500)', type = 'l', col = 'red', xlim = c(0, 500), ylim = c(0.74, 0.86), ylab = 'Accuracy')
lines(tempTest, type = 'l', col = 'blue')
legend("topright", inset = 0.15, title = "datasets", c("train","test"), fill = c("red","blue"), horiz = FALSE)
plot(tempTrain - tempTest, type = 'l', col = 'cyan', main = 'Train Test accuracy (gSearch 1:500)', xlim = c(0, 500))
plot(tempTrain, main = 'Learning Curve - rForest (gSearch 1:500)', type = 'l', col = 'red', xlim = c(0, 200), ylim = c(0.74, 0.86), ylab = 'Accuracy')
lines(tempTest, type = 'l', col = 'blue')
legend("topright", inset = 0.15, title = "datasets", c("train","test"), fill = c("red","blue"), horiz = FALSE)
plot(tempTrain, main = 'Learning Curve - rForest (gSearch 1:500)', type = 'l', col = 'red', xlim = c(0, 250), ylim = c(0.74, 0.86), ylab = 'Accuracy')
lines(tempTest, type = 'l', col = 'blue')
legend("topright", inset = 0.15, title = "datasets", c("train","test"), fill = c("red","blue"), horiz = FALSE)
plot(tempTrain, main = 'Learning Curve - rForest (gSearch 1:500)', type = 'l', col = 'red', xlim = c(0, 245), ylim = c(0.74, 0.86), ylab = 'Accuracy')
plot(tempTrain, main = 'Learning Curve - rForest (gSearch 1:500)', type = 'l', col = 'red', xlim = c(0, 243), ylim = c(0.74, 0.86), ylab = 'Accuracy')
plot(tempTrain, main = 'Learning Curve - rForest (gSearch 1:500)', type = 'l', col = 'red', xlim = c(0, 240), ylim = c(0.74, 0.86), ylab = 'Accuracy')
plot(tempTrain, main = 'Learning Curve - rForest (gSearch 1:500)', type = 'l', col = 'red', xlim = c(0, 241), ylim = c(0.74, 0.86), ylab = 'Accuracy')
lines(tempTest, type = 'l', col = 'blue')
legend("topright", inset = 0.15, title = "datasets", c("train","test"), fill = c("red","blue"), horiz = FALSE)
plot(tempTrain, main = 'Learning Curve - rForest (gSearch 1:500)', type = 'l', col = 'red', xlim = c(0, 240.5), ylim = c(0.74, 0.86), ylab = 'Accuracy')
lines(tempTest, type = 'l', col = 'blue')
plot(tempTrain, main = 'Learning Curve - rForest (gSearch 1:250)', type = 'l', col = 'red', xlim = c(0, 240.5), ylim = c(0.74, 0.86), ylab = 'Accuracy')
lines(tempTest, type = 'l', col = 'blue')
legend("topright", inset = 0.15, title = "datasets", c("train","test"), fill = c("red","blue"), horiz = FALSE)
plot(tempTrain[1:250], main = 'Learning Curve - rForest (gSearch 1:250)', type = 'l', col = 'red', xlim = c(0, 240.5), ylim = c(0.74, 0.86), ylab = 'Accuracy')
plot(tempTrain[1:250], main = 'Learning Curve - rForest (gSearch 1:550)', type = 'l', col = 'red', xlim = c(0, 240.5), ylim = c(0.74, 0.86), ylab = 'Accuracy')
plot(tempTrain[1:250], main = 'Learning Curve - rForest (gSearch 1:550)', type = 'l', col = 'red', xlim = c(0, 240.5), ylim = c(0.74, 0.86), ylab = 'Accuracy')
lines(tempTest[1:50], type = 'l', col = 'blue')
lines(tempTest[1:250], type = 'l', col = 'blue')
plot(tempTrain[1:250], main = 'Learning Curve - rForest (gSearch 1:250)', type = 'l', col = 'red', xlim = c(0, 240.5), ylim = c(0.74, 0.86), ylab = 'Accuracy')
lines(tempTest[1:250], type = 'l', col = 'blue')
legend("topright", inset = 0.15, title = "datasets", c("train","test"), fill = c("red","blue"), horiz = FALSE)
## Does removing the installer attributes and the year of construction was a good approach?
mean(tempTrain)                                        # [1] 0.7704291
mean(tempTest)                                         # [2] 0.7526957
max(tempTest)                                          # [1]
max(tempTrain)                                         # [1]
confusionMatrix(table(pred2, test$status_group))
confusionMatrix(table(pred, test$status_group))
confusionMatrix(table(pred, test$status_group))
# ------------------------------------------------------ Testing and Validation Function
# randomForest and RWeka classifiers
predVal = function(model, test) {
predict = predict(model, test)
real = test$status_group
print(sum(predict == real)/nrow(test))
confusionMatrix(table(predict, real))
}
predVal(tempTrain, train)
# ------------------------------------------------------ Testing and Validation Function
# randomForest and RWeka classifiers
predVal = function(model, test) {
predict = model
real = test$status_group
print(sum(predict == real)/nrow(test))
confusionMatrix(table(predict, real))
}
# randomForest - Grid Search
predVal = function(model, test) {
predict = model
real = test$status_group
print(sum(predict == real)/nrow(test))
confusionMatrix(table(predict, real))
}
predVal(tempTrain, train)
predVal(pred2, train)
predVal(pred, test)
library(readr)
trainX = read_csv("~/Documents/OneDrive/Acadêmico/ESPM/Semestre V/Tel 03.3009 - Machine Learning e Analytics/Trabalhos/taarifaProblem/data/trainX.csv")
trainX$id = NULL
trainY = read_csv("~/Documents/OneDrive/Acadêmico/ESPM/Semestre V/Tel 03.3009 - Machine Learning e Analytics/Trabalhos/taarifaProblem/data/trainY.csv")
trainY$id = NULL
dataset = cbind(trainX, trainY)
rm(trainX)
rm(trainY)
View(dataset)
dataset[1:3, c(33, 34)]
sum(dataset$quality_group == dataset$quantity)
unique(dataset$quantity)
unique(dataset$quantity_group)
dataset[1:3, c(33, 34)]
dataset[1:3, c(33, 34)]
dataset[1:3, c(33, 34)]
dataset[1:3, c(33, 34)]
dataset[1:3, c(33, 34)]
sum(dataset$amount_tsh == 0)/nrow(dataset)
sum(is.na(dataset$amount_tsh))
library(readr)
trainX = read_csv("~/Documents/OneDrive/Acadêmico/ESPM/Semestre V/Tel 03.3009 - Machine Learning e Analytics/Trabalhos/taarifaProblem/data/trainX.csv")
trainX$id = NULL
trainY = read_csv("~/Documents/OneDrive/Acadêmico/ESPM/Semestre V/Tel 03.3009 - Machine Learning e Analytics/Trabalhos/taarifaProblem/data/trainY.csv")
trainY$id = NULL
dataset = cbind(trainX, trainY)
rm(trainX)
rm(trainY)
unique(dataset$quantity))
unique(dataset$quantity)
unique(dataset$quantity_group)
library(readr)
trainX = read_csv("~/Documents/OneDrive/Acadêmico/ESPM/Semestre V/Tel 03.3009 - Machine Learning e Analytics/Trabalhos/taarifaProblem/data/trainX.csv")
trainX$id = NULL
trainY = read_csv("~/Documents/OneDrive/Acadêmico/ESPM/Semestre V/Tel 03.3009 - Machine Learning e Analytics/Trabalhos/taarifaProblem/data/trainY.csv")
trainY$id = NULL
dataset = cbind(trainX, trainY)
rm(trainX)
rm(trainY)
sum(dataset$amount_tsh == 0)/nrow(dataset)
sum(is.na(dataset$amount_tsh))
dataset[1:5, c(33, 34)]
library(readr)
trainX = read_csv("~/Documents/OneDrive/Acadêmico/ESPM/Semestre V/Tel 03.3009 - Machine Learning e Analytics/Trabalhos/taarifaProblem/data/trainX.csv")
trainX$id = NULL
trainY = read_csv("~/Documents/OneDrive/Acadêmico/ESPM/Semestre V/Tel 03.3009 - Machine Learning e Analytics/Trabalhos/taarifaProblem/data/trainY.csv")
trainY$id = NULL
dataset = cbind(trainX, trainY)
rm(trainX)
rm(trainY)
sum(dataset$amount_tsh == 0)/nrow(dataset)
sum(is.na(dataset$amount_tsh))
library(readr)
trainX = read_csv("~/Documents/OneDrive/Acadêmico/ESPM/Semestre V/Tel 03.3009 - Machine Learning e Analytics/Trabalhos/taarifaProblem/data/trainX.csv")
trainX$id = NULL
trainY = read_csv("~/Documents/OneDrive/Acadêmico/ESPM/Semestre V/Tel 03.3009 - Machine Learning e Analytics/Trabalhos/taarifaProblem/data/trainY.csv")
trainY$id = NULL
dataset = cbind(trainX, trainY)
rm(trainX)
rm(trainY)
sum(dataset$amount_tsh == 0)/nrow(dataset)
sum(is.na(dataset$amount_tsh))
dataset[1:5, c(33, 34)]
sum(is.na(dataset$quantity))
sum(is.na(dataset$quantity_group))
dataset$quantity_group = NULL
dataset$quantity_group = NULL
dataset$quantity_group = NULL
sum(is.na(dataset$quantity))
sum(is.na(dataset$quantity_group))
dataset[1:5, c(33, 34)]
library(readr)
trainX = read_csv("~/Documents/OneDrive/Acadêmico/ESPM/Semestre V/Tel 03.3009 - Machine Learning e Analytics/Trabalhos/taarifaProblem/data/trainX.csv")
trainX$id = NULL
trainY = read_csv("~/Documents/OneDrive/Acadêmico/ESPM/Semestre V/Tel 03.3009 - Machine Learning e Analytics/Trabalhos/taarifaProblem/data/trainY.csv")
trainY$id = NULL
dataset = cbind(trainX, trainY)
rm(trainX)
rm(trainY)
dataset[1:5, c(32, 34)]
dataset[1:5, c(dataset$quantity, dataset$quantity_group)]
dataset[1:5, c('dataset$quantity', 'dataset$quantity_group')]
dataset[1:5, c('quantity', 'quantity_group')]
unique(dataset$quantity)
uniquedataset$quantity_group)
unique(dataset$quantity)
unique(dataset$quantity_group)
sum(dataset$gps_height == 0)
sum(dataset$gps_height == 0)/nrow(dataset)
sum(is.na(dataset$gps_height))
sum(dataset$gps_height == 0)/nrow(dataset)
sum(is.na(dataset$gps_height))
sum(is.na(dataset$basin))
sum(is.na(dataset$district_code))
sum(is.na(dataset$region))
sum(is.na(dataset$region_code))
sum(is.na(dataset$lga))
sum(is.na(dataset$ward))
sum(is.na(dataset$subvillage))
length(unique(dataset$scheme_management))
length(unique(dataset$scheme_name))
sum(is.na(dataset$scheme_management))
sum(is.na(dataset$scheme_name))
dataset[1:5, c('payment', 'payment_type')]
sum(is.na(dataset$payment))
sum(is.na(dataset$payment_type))
unique(dataset$payment)
unique(dataset$payment_type)
dataset[1:5, c('waterpoint_type', 'waterpoint_type_group')]
sum(is.na(dataset$waterpoint_type))
sum(is.na(dataset$waterpoint_type_group))
length(unique(dataset$waterpoint_type))
length(unique(dataset$waterpoint_type_group))
library(readr)
source('~/Documents/OneDrive/Acadêmico/ESPM/Semestre V/Tel 03.3009 - Machine Learning e Analytics/Trabalhos/taarifaProblem/scripts/dataManipulation/dataImport.R', echo=TRUE)
source('~/Documents/OneDrive/Acadêmico/ESPM/Semestre V/Tel 03.3009 - Machine Learning e Analytics/Trabalhos/taarifaProblem/scripts/dataManipulation/attributesRemoval.R', echo=TRUE)
source('~/Documents/OneDrive/Acadêmico/ESPM/Semestre V/Tel 03.3009 - Machine Learning e Analytics/Trabalhos/taarifaProblem/scripts/dataManipulation/dataSeparation.R', echo=TRUE)
source('~/Documents/OneDrive/Acadêmico/ESPM/Semestre V/Tel 03.3009 - Machine Learning e Analytics/Trabalhos/taarifaProblem/scripts/dataManipulation/dataImport.R', echo=TRUE)
source('~/Documents/OneDrive/Acadêmico/ESPM/Semestre V/Tel 03.3009 - Machine Learning e Analytics/Trabalhos/taarifaProblem/scripts/dataManipulation/attributesRemoval.R', echo=TRUE)
source('~/Documents/OneDrive/Acadêmico/ESPM/Semestre V/Tel 03.3009 - Machine Learning e Analytics/Trabalhos/taarifaProblem/scripts/dataManipulation/dataProcessing.R', echo=TRUE)
## Checking the type o Y attribute
sapply(dataset, class)                                  # [1] 'character'
## Char to Factor
for (i in 1:3) {
dataset[, i] = as.factor(paste(dataset[, i]))
}
for (i in 5:ncol(dataset)) {
dataset[, i] = as.factor(paste(dataset[, i]))
}
rm(i)
## checking the unique attributes length
length(unique(dataset[, 1]))
length(unique(dataset[, 2]))
length(unique(dataset[, 3]))
length(unique(dataset[, 4]))
length(unique(dataset[, 5]))
length(unique(dataset[, 6]))
length(unique(dataset[, 7]))
length(unique(dataset[, 8]))
length(unique(dataset[, 9]))
length(unique(dataset[, 10]))
length(unique(dataset[, 11]))
length(unique(dataset[, 12]))
source('~/Documents/OneDrive/Acadêmico/ESPM/Semestre V/Tel 03.3009 - Machine Learning e Analytics/Trabalhos/taarifaProblem/scripts/dataManipulation/dataSeparation.R', echo=TRUE)
myFormula = train$status_group ~ .
library(randomForest)
rForest = randomForest(myFormula, data = train, importance = TRUE, do.trace = FALSE)
## Checking the type o Y attribute
sapply(dataset, class)                                  # [1] 'character'
sapply(train, class)
length(unique(dataset[, 4]))
length(unique(train[, 4]))
train$management_group = as.factor(paste(management_group))
train$management_group = as.factor(paste(train$management_group))
test$management_group = as.factor(paste(test$management_group))
sapply(train, class)
rForest = randomForest(myFormula, data = train, importance = TRUE, do.trace = FALSE)
predVal(rForest, train)
# ------------------------------------------------------ Testing and Validation Function
# randomForest
predVal = function(model, test) {
predict = predict(model, test)
real = test$status_group
print(sum(predict == real)/nrow(test))
confusionMatrix(table(predict, real))
}
predVal(rForest, train)
predVal(rForest, test)
# Grid Search and Hyperparameter
tempTest = c()
tempTrain = c()
for (i in 1:700) {
rForest = randomForest(myFormula, data = train, importance = TRUE, do.trace = FALSE, ntree = i, mtry = 5, nodesize = (abs(i - 90)))
pred = predict(rForest, train)
pred1 = predict(rForest, test)
print(i)
tempTrain[i] = (sum(pred == train$status_group)/nrow(train))
tempTest[i] = (sum(pred1 == test$status_group)/nrow(test))
print(tempTest[i])
if (tempTest[i] >= 0.82) {
break;
}
}
plot(tempTrain[1:250], main = 'Learning Curve - rForest (gSearch 1:250)', type = 'l', col = 'red', xlim = c(0, 240.5), ylim = c(0.74, 0.86), ylab = 'Accuracy')
lines(tempTest[1:250], type = 'l', col = 'blue')
plot(tempTrain[1:250], main = 'Learning Curve - rForest (gSearch 1:250)', type = 'l', col = 'red', xlim = c(0, 50), ylim = c(0.74, 0.86), ylab = 'Accuracy')
lines(tempTest[1:250], type = 'l', col = 'blue')
plot(tempTrain[1:250], main = 'Learning Curve - rForest (gSearch 1:250)', type = 'l', col = 'red', xlim = c(0, 240.5), ylim = c(0.74, 0.86), ylab = 'Accuracy')
lines(tempTest[1:250], type = 'l', col = 'blue')
plot(tempTrain[1:250], main = 'Learning Curve - rForest (gSearch 1:250)', type = 'l', col = 'red', xlim = c(0, 500), ylim = c(0.74, 0.86), ylab = 'Accuracy')
lines(tempTest[1:250], type = 'l', col = 'blue')
legend("topright", inset = 0.15, title = "datasets", c("train","test"), fill = c("red","blue"), horiz = FALSE)
240.5
plot(tempTrain[1:250], main = 'Learning Curve - rForest (gSearch 1:250)', type = 'l', col = 'red', xlim = c(0, 240.5), ylim = c(0.74, 0.86), ylab = 'Accuracy')
lines(tempTest[1:250], type = 'l', col = 'blue')
plot(tempTrain - tempTest, type = 'l', col = 'cyan', main = 'Train Test accuracy (gSearch 1:500)', xlim = c(0, 500))
source('~/Documents/OneDrive/Acadêmico/ESPM/Semestre V/Tel 03.3009 - Machine Learning e Analytics/Trabalhos/taarifaProblem/scripts/dataManipulation/attributesRemoval.R', echo=TRUE)
source('~/Documents/OneDrive/Acadêmico/ESPM/Semestre V/Tel 03.3009 - Machine Learning e Analytics/Trabalhos/taarifaProblem/scripts/dataManipulation/dataProcessing.R', echo=TRUE)
## The summing of NA values
sum(is.na(dataset))                                     # [1] 7532
## Removing those 0 values
dataset$construction_year[dataset$construction_year == 0] = NA
library(readr)
trainX = read_csv("~/Documents/OneDrive/Acadêmico/ESPM/Semestre V/Tel 03.3009 - Machine Learning e Analytics/Trabalhos/taarifaProblem/data/trainX.csv")
trainX$id = NULL
trainY = read_csv("~/Documents/OneDrive/Acadêmico/ESPM/Semestre V/Tel 03.3009 - Machine Learning e Analytics/Trabalhos/taarifaProblem/data/trainY.csv")
trainY$id = NULL
dataset = cbind(trainX, trainY)
rm(trainX)
rm(trainY)
source('~/Documents/OneDrive/Acadêmico/ESPM/Semestre V/Tel 03.3009 - Machine Learning e Analytics/Trabalhos/taarifaProblem/scripts/dataManipulation/attributesRemoval.R', echo=TRUE)
sum(is.na(dataset$construction_year))
dataset = na.omit(dataset)
## Checking the type o Y attribute
sapply(dataset, class)                                  # [1] 'character'
## Char to Factor
for (i in 1:3) {
dataset[, i] = as.factor(paste(dataset[, i]))
}
for (i in 5:ncol(dataset)) {
dataset[, i] = as.factor(paste(dataset[, i]))
}
## Checking the type o Y attribute
sapply(dataset, class)                                  # [1] 'character'
## Char to Factor
for (i in 1:4) {
dataset[, i] = as.factor(paste(dataset[, i]))
}
## Checking the type o Y attribute
sapply(dataset, class)                                  # [1] 'character'
set.seed(1234)
library(caret)
trainIndex = createDataPartition(dataset$status_group, p = 0.8, list = FALSE, times = 1)
train = dataset[trainIndex,]
test = dataset[-trainIndex,]
rm(trainIndex)
rm(dataset)
rm(i)
myFormula = train$status_group ~ .
library(randomForest)
for (i in 1:700) {
for (j in ncol(train)) {
rForest = randomForest(myFormula, data = train, importance = TRUE, do.trace = FALSE, ntree = i, mtry = j, nodesize = (abs(i - 90)))
pred = predict(rForest, train)
pred1 = predict(rForest, test)
print(i)
tempTrain[j] = (sum(pred == train$status_group)/nrow(train))
tempTest[j] = (sum(pred1 == test$status_group)/nrow(test))
print(tempTest[j])
if (tempTest[j] >= 0.82) {
break;
}
}
}
for (i in 1:700) {
for (j in 1:ncol(train)) {
rForest = randomForest(myFormula, data = train, importance = TRUE, do.trace = FALSE, ntree = i, mtry = j, nodesize = (abs(i - 90)))
pred = predict(rForest, train)
pred1 = predict(rForest, test)
print(i)
tempTrain[j] = (sum(pred == train$status_group)/nrow(train))
tempTest[j] = (sum(pred1 == test$status_group)/nrow(test))
print(tempTest[j])
if (tempTest[j] >= 0.82) {
break;
}
}
}
# Grid Search and Hyperparameter
tempTest = c()
tempTrain = c()
for (i in 1:700) {
for (j in 1:ncol(train)) {
rForest = randomForest(myFormula, data = train, importance = TRUE, do.trace = FALSE, ntree = i, mtry = j, nodesize = (abs(i - 90)))
pred = predict(rForest, train)
pred1 = predict(rForest, test)
print(i)
tempTrain[j] = (sum(pred == train$status_group)/nrow(train))
tempTest[j] = (sum(pred1 == test$status_group)/nrow(test))
print(tempTest[j])
if (tempTest[j] >= 0.82) {
break;
}
}
}
plot(tempTrain[1:250], main = 'Learning Curve - rForest (gSearch 1:250)', type = 'l', col = 'red', xlim = c(0, 240.5), ylim = c(0.74, 0.86), ylab = 'Accuracy')
lines(tempTest[1:250], type = 'l', col = 'blue')
legend("topright", inset = 0.15, title = "datasets", c("train","test"), fill = c("red","blue"), horiz = FALSE)
plot(tempTrain[1:50], main = 'Learning Curve - rForest (gSearch 1:250)', type = 'l', col = 'red', xlim = c(0, 240.5), ylim = c(0.74, 0.86), ylab = 'Accuracy')
lines(tempTest[1:50], type = 'l', col = 'blue')
plot(tempTrain[1:250], main = 'Learning Curve - rForest (gSearch 1:250)', type = 'l', col = 'red', xlim = c(0, 20), ylim = c(0.74, 0.86), ylab = 'Accuracy')
lines(tempTest[1:250], type = 'l', col = 'blue')
legend("topright", inset = 0.15, title = "datasets", c("train","test"), fill = c("red","blue"), horiz = FALSE)
for (i in 1:500) {
for (j in 1:ncol(train)) {
rForest = randomForest(myFormula, data = train, importance = TRUE, do.trace = FALSE, ntree = i, mtry = j, nodesize = (abs(i - 90)))
pred = predict(rForest, train)
pred1 = predict(rForest, test)
print(i)
tempTrain[j] = (sum(pred == train$status_group)/nrow(train))
tempTest[j] = (sum(pred1 == test$status_group)/nrow(test))
print(tempTest[j])
if (tempTest[j] >= 0.82) {
break;
}
}
}
for (i in 1:500) {
for (j in 1:ncol(train)) {
rForest = randomForest(myFormula, data = train, importance = TRUE, do.trace = FALSE, ntree = i, mtry = j, nodesize = (abs(i - 90)))
pred = predict(rForest, train)
pred1 = predict(rForest, test)
print(i, '.', j)
tempTrain[j] = (sum(pred == train$status_group)/nrow(train))
tempTest[j] = (sum(pred1 == test$status_group)/nrow(test))
print(tempTest[j])
if (tempTest[j] >= 0.82) {
break;
}
}
}
for (i in 1:500) {
for (j in 1:ncol(train)) {
rForest = randomForest(myFormula, data = train, importance = TRUE, do.trace = FALSE, ntree = i, mtry = j, nodesize = (abs(i - 90)))
pred = predict(rForest, train)
pred1 = predict(rForest, test)
print(paste(i, j, sep = '.'))
tempTrain[j] = (sum(pred == train$status_group)/nrow(train))
tempTest[j] = (sum(pred1 == test$status_group)/nrow(test))
print(tempTest[j])
if (tempTest[j] >= 0.82) {
break;
}
}
}
plot(tempTrain[1:1300], main = 'Learning Curve - rForest (gSearch 1:250)', type = 'l', col = 'red', xlim = c(0, 1300), ylim = c(0.74, 0.86), ylab = 'Accuracy')
lines(tempTest[1:1300], type = 'l', col = 'blue')
legend("topright", inset = 0.15, title = "datasets", c("train","test"), fill = c("red","blue"), horiz = FALSE)
250
plot(tempTrain[1:250], main = 'Learning Curve - rForest (gSearch 1:250)', type = 'l', col = 'red', xlim = c(0, 500), ylim = c(0.74, 0.86), ylab = 'Accuracy')
lines(tempTest[1:250], type = 'l', col = 'blue')
legend("topright", inset = 0.15, title = "datasets", c("train","test"), fill = c("red","blue"), horiz = FALSE)
plot(tempTrain - tempTest, type = 'l', col = 'cyan', main = 'Train Test accuracy (gSearch 1:500)', xlim = c(0, 500))
rm(pred2)
View(tempTest)
View(tempTrain)
