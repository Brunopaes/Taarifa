pred = predict(rForest, train)
pred1 = predict(rForest, test)
print(i)
tempTrain[j] = (sum(pred == train$status_group)/nrow(train))
tempTest[j] = (sum(pred1 == test$status_group)/nrow(test))
print(tempTest[j])
if (tempTest[j] >= 0.82) {
break;
}
}
}
plot(tempTrain[1:250], main = 'Learning Curve - rForest (gSearch 1:250)', type = 'l', col = 'red', xlim = c(0, 240.5), ylim = c(0.74, 0.86), ylab = 'Accuracy')
lines(tempTest[1:250], type = 'l', col = 'blue')
legend("topright", inset = 0.15, title = "datasets", c("train","test"), fill = c("red","blue"), horiz = FALSE)
plot(tempTrain[1:50], main = 'Learning Curve - rForest (gSearch 1:250)', type = 'l', col = 'red', xlim = c(0, 240.5), ylim = c(0.74, 0.86), ylab = 'Accuracy')
lines(tempTest[1:50], type = 'l', col = 'blue')
plot(tempTrain[1:250], main = 'Learning Curve - rForest (gSearch 1:250)', type = 'l', col = 'red', xlim = c(0, 20), ylim = c(0.74, 0.86), ylab = 'Accuracy')
lines(tempTest[1:250], type = 'l', col = 'blue')
legend("topright", inset = 0.15, title = "datasets", c("train","test"), fill = c("red","blue"), horiz = FALSE)
for (i in 1:500) {
for (j in 1:ncol(train)) {
rForest = randomForest(myFormula, data = train, importance = TRUE, do.trace = FALSE, ntree = i, mtry = j, nodesize = (abs(i - 90)))
pred = predict(rForest, train)
pred1 = predict(rForest, test)
print(i)
tempTrain[j] = (sum(pred == train$status_group)/nrow(train))
tempTest[j] = (sum(pred1 == test$status_group)/nrow(test))
print(tempTest[j])
if (tempTest[j] >= 0.82) {
break;
}
}
}
for (i in 1:500) {
for (j in 1:ncol(train)) {
rForest = randomForest(myFormula, data = train, importance = TRUE, do.trace = FALSE, ntree = i, mtry = j, nodesize = (abs(i - 90)))
pred = predict(rForest, train)
pred1 = predict(rForest, test)
print(i, '.', j)
tempTrain[j] = (sum(pred == train$status_group)/nrow(train))
tempTest[j] = (sum(pred1 == test$status_group)/nrow(test))
print(tempTest[j])
if (tempTest[j] >= 0.82) {
break;
}
}
}
for (i in 1:500) {
for (j in 1:ncol(train)) {
rForest = randomForest(myFormula, data = train, importance = TRUE, do.trace = FALSE, ntree = i, mtry = j, nodesize = (abs(i - 90)))
pred = predict(rForest, train)
pred1 = predict(rForest, test)
print(paste(i, j, sep = '.'))
tempTrain[j] = (sum(pred == train$status_group)/nrow(train))
tempTest[j] = (sum(pred1 == test$status_group)/nrow(test))
print(tempTest[j])
if (tempTest[j] >= 0.82) {
break;
}
}
}
plot(tempTrain[1:1300], main = 'Learning Curve - rForest (gSearch 1:250)', type = 'l', col = 'red', xlim = c(0, 1300), ylim = c(0.74, 0.86), ylab = 'Accuracy')
lines(tempTest[1:1300], type = 'l', col = 'blue')
legend("topright", inset = 0.15, title = "datasets", c("train","test"), fill = c("red","blue"), horiz = FALSE)
250
plot(tempTrain[1:250], main = 'Learning Curve - rForest (gSearch 1:250)', type = 'l', col = 'red', xlim = c(0, 500), ylim = c(0.74, 0.86), ylab = 'Accuracy')
lines(tempTest[1:250], type = 'l', col = 'blue')
legend("topright", inset = 0.15, title = "datasets", c("train","test"), fill = c("red","blue"), horiz = FALSE)
plot(tempTrain - tempTest, type = 'l', col = 'cyan', main = 'Train Test accuracy (gSearch 1:500)', xlim = c(0, 500))
rm(pred2)
View(tempTest)
View(tempTrain)
View(dataset)
library(readr)
testX <- read_csv("~/Documents/OneDrive/Acadêmico/ESPM/Semestre V/Tel 03.3009 - Machine Learning e Analytics/Trabalhos/taarifaProblem/data/Test set values  - 702ddfc5-68cd-4d1d-a0de-f5f566f76d91.csv")
View(testX)
testX$id = NULL
source('~/Documents/OneDrive/Acadêmico/ESPM/Semestre V/Tel 03.3009 - Machine Learning e Analytics/Trabalhos/taarifaProblem/scripts/dataManipulation/attributesRemoval.R', echo=TRUE)
source('~/Documents/OneDrive/Acadêmico/ESPM/Semestre V/Tel 03.3009 - Machine Learning e Analytics/Trabalhos/taarifaProblem/scripts/dataManipulation/attributesRemoval.R', echo=TRUE)
source('~/Documents/OneDrive/Acadêmico/ESPM/Semestre V/Tel 03.3009 - Machine Learning e Analytics/Trabalhos/taarifaProblem/scripts/dataManipulation/attributesRemoval.R', echo=TRUE)
source('~/Documents/OneDrive/Acadêmico/ESPM/Semestre V/Tel 03.3009 - Machine Learning e Analytics/Trabalhos/taarifaProblem/scripts/dataManipulation/attributesRemoval.R', echo=TRUE)
View(dataset)
# ------------------------------------------------------ Testing and Validation Function
# randomForest
predVal = function(model, test) {
predict = predict(model, test)
real = test$status_group
print(sum(predict == real)/nrow(test))
table(predict, real)
}
myFormula = dataset$status_group ~ .
library(randomForest)
rForest = randomForest(myFormula, data = dataset, importance = TRUE, do.trace = TRUE, ntree = 1)
for (i in 1:ncol(dataset)) {
dataset[, i] = as.factor(paste(dataset[, i]))
}
## Checking the type o Y attribute
sapply(dataset, class)                                  # [1] 'character'
unique(dataset$basin)
unique(testX$basin)
unique(testX$scheme_management)
unique(dataset$scheme_management)
unique(dataset$extraction_type_class)
unique(testX$extraction_type_class)
unique(testX$management_group)
unique(dataset$management_group)
unique(dataset$payment_type)
unique(testX$payment_type)
testX$payment_type = as.factor(paste(testX$payment_type))
unique(testX$payment_type)
unique(dataset$payment_type)
unique(dataset$source_class)
unique(testX$source_class)
testX$source_class = as.factor(paste(testX$source_class))
unique(testX$source_class)
unique(dataset$source_class)
dataset$management_group = NULL
testX$management_group = NULL
myFormula = dataset$status_group ~ .
library(randomForest)
rForest = randomForest(myFormula, data = dataset, importance = TRUE, do.trace = TRUE, ntree = 1)
predVal(rForest, dataset)
pred = predict(rForest, testX)
sum(is.na(testX$amount_tsh))                          # [1] 0
## Conclusion: This attribute is inconsistent! And should be removed
testX$amount_tsh = NULL
sum(is.na(dataset$amount_tsh))                          # [1] 0
## Conclusion: This attribute is inconsistent! And should be removed
dataset$amount_tsh = NULL
## Conclusion: Simplify the model
dataset$quantity_group = NULL
## Conclusion: Simplify the model
dataset$water_quality = NULL
## Conclusion: These attributes, although 'interesting', due to their low generalization,
## make the model very complex.
dataset$longitude = NULL
dataset$latitude = NULL
dataset$lga = NULL
dataset$ward = NULL
dataset$subvillage = NULL
# Misc Attributes
## Does the recorded date impact the model?
dataset$date_recorded = NULL
## Does the recorded by impact the model?
dataset$recorded_by = NULL
## Removing the waterpoint name - does the name of the waterpoint influences in the status of the same?
dataset$wpt_name = NULL
## Conclusion: The scheme_name attribute, when compared to the scheme_management,
## besides having many more missing values (NA Values), is somewhat more complex.
## Because of this, it is not very influential in the model and should be removed.
dataset$scheme_name = NULL
## Conclusion: Simplify the model.
dataset$waterpoint_type = NULL
source('~/Documents/OneDrive/Acadêmico/ESPM/Semestre V/Tel 03.3009 - Machine Learning e Analytics/Trabalhos/taarifaProblem/scripts/dataManipulation/dataImport.R', echo=TRUE)
source('~/Documents/OneDrive/Acadêmico/ESPM/Semestre V/Tel 03.3009 - Machine Learning e Analytics/Trabalhos/taarifaProblem/scripts/dataManipulation/dataImport.R', echo=TRUE)
source('~/Documents/OneDrive/Acadêmico/ESPM/Semestre V/Tel 03.3009 - Machine Learning e Analytics/Trabalhos/taarifaProblem/scripts/dataManipulation/dataImport.R', echo=TRUE)
dataset$amount_tsh = NULL
dataset$funder = NULL
dataset$day_recorded = NULL
dataset$gps_height = NULL
dataset$installer = NULL
dataset$latitude = NULL
dataset$longitude = NULL
dataset$wpt_name = NULL
dataset$num_private = NULL
dataset$population = NULL
dataset$recorded_by = NULL
dataset$lga = NULL
dataset$ward = NULL
dataset$public_meeting = NULL
dataset$sub_village = NULL
dataset$scheme_name = NULL
dataset$permit = NULL
dataset$date_recorded = NULL
dataset$subvillage = NULL
dataset$construction_year = NULL
dataset$extraction_type = NULL
View(dataset)
unique(dataset$basin)
unique(dataset$region)
unique(dataset$region_code)
unique(dataset$scheme_management)
unique(dataset$extraction_type_group)
unique(dataset$extraction_type_class)
unique(dataset$management)
unique(dataset$management_group)
unique(dataset$payment)
unique(dataset$payment_type)
unique(dataset$water_quality)
unique(dataset$quality_group)
unique(dataset$source)
unique(dataset$source_type)
unique(dataset$source_class)
unique(dataset$waterpoint_type)
unique(dataset$waterpoint_type_group)
unique(dataset$district_code)
## The summing of NA values
sum(is.na(dataset))                                     # [1] 7532
## Checking the type o Y attribute
sapply(dataset, class)                                  # [1] 'character'
## Char to Factor
for (i in 1:2) {
dataset[, i] = as.factor(paste(dataset[, i]))
}
## Checking the type o Y attribute
sapply(dataset, class)                                  # [1] 'character'
unique(dataset$basin)
for (i in 5:ncol(testX)) {
testX[, i] = as.factor(paste(testX[, i]))
}
for (i in 5:ncol(testX)) {
dataset[, i] = as.factor(paste(dataset[, i]))
}
for (i in 5:ncol(dataset)) {
dataset[, i] = as.factor(paste(dataset[, i]))
}
## Checking the type o Y attribute
sapply(dataset, class)                                  # [1] 'character'
myFormula = dataset$status_group ~ .
library(randomForest)
rForest = randomForest(myFormula, data = dataset, importance = TRUE, do.trace = TRUE, ntree = 1)
predVal(rForest, dataset)
# ------------------------------------------------------ Testing and Validation Function
# randomForest
predVal = function(model, test) {
predict = predict(model, test)
real = test$status_group
print(sum(predict == real)/nrow(test))
confusionMatrix(table(predict, real))
}
predVal(rForest, dataset)
# ------------------------------------------------------ Testing and Validation Function
# randomForest
predVal = function(model, test) {
predict = predict(model, test)
real = test$status_group
print(sum(predict == real)/nrow(test))
table(predict, real)
}
predVal(rForest, dataset)
testX <- read.csv("~/Documents/OneDrive/Acad\x0Amico/ESPM/Semestre V/Tel 03.3009 - Machine Learning e Analytics/Trabalhos/taarifaProblem/data/testX.csv")
View(testX)
library(readr)
testX <- read.csv("~/Documents/OneDrive/Acad\x0Amico/ESPM/Semestre V/Tel 03.3009 - Machine Learning e Analytics/Trabalhos/taarifaProblem/data/testX.csv")
View(testX)
library(readr)
testX <- read_csv("~/Documents/OneDrive/Acadêmico/ESPM/Semestre V/Tel 03.3009 - Machine Learning e Analytics/Trabalhos/taarifaProblem/data/testX.csv")
View(testX)
testX$amount_tsh = NULL
testX$funder = NULL
testX$day_recorded = NULL
testX$gps_height = NULL
testX$installer = NULL
testX$latitude = NULL
testX$longitude = NULL
testX$wpt_name = NULL
testX$num_private = NULL
testX$population = NULL
testX$recorded_by = NULL
testX$lga = NULL
testX$ward = NULL
testX$public_meeting = NULL
testX$sub_village = NULL
testX$scheme_name = NULL
testX$permit = NULL
testX$date_recorded = NULL
testX$subvillage = NULL
testX$id = NULL
testX$construction_year = NULL
testX$extraction_type = NULL
pred = predict(rForest, testX)
rm(testX)
library(readr)
testX <- read_csv("~/Documents/OneDrive/Acadêmico/ESPM/Semestre V/Tel 03.3009 - Machine Learning e Analytics/Trabalhos/taarifaProblem/data/testX.csv")
View(testX)
testX$amount_tsh = NULL
testX$funder = NULL
testX$day_recorded = NULL
testX$gps_height = NULL
testX$installer = NULL
testX$latitude = NULL
testX$longitude = NULL
testX$wpt_name = NULL
testX$num_private = NULL
testX$population = NULL
testX$recorded_by = NULL
testX$lga = NULL
testX$ward = NULL
testX$public_meeting = NULL
testX$sub_village = NULL
testX$scheme_name = NULL
testX$permit = NULL
testX$date_recorded = NULL
testX$subvillage = NULL
testX$id = NULL
testX$construction_year = NULL
testX$extraction_type = NULL
pred = predict(rForest, testX)
testX$region_code = NULL
dataset$region_code = NULL
rForest = randomForest(myFormula, data = dataset, importance = TRUE, do.trace = TRUE, ntree = 1)
predVal(rForest, dataset)
pred = predict(rForest, testX)
testX$basin
basin = testX$basin
basin
basin = as.factor(paste(basin))
basin
View(basin)
region = as.factor(paste(testX$region))
region
scheme_management = as.factor(paste(scheme_management))
scheme_management = as.factor(paste(testX$scheme_management))
scheme_management
extraction_type_group = as.factor(paste(extraction_type_group))
rm(scheme_management)
rm(region)
rm(basin)
testX$basin = as.factor(paste(testX$basin)
)
testX$basin
testX$region = as.factor(paste(testX$region))
testX$scheme_management = as.factor(paste(testX$scheme_management))
testX$extraction_type_group = as.factor(paste(testX$extraction_type_group))
testX$extraction_type_class = as.factor(paste(testX$extraction_type_class))
testX$management = as.factor(paste(testX$management))
testX$management_group = as.factor(paste(testX$management_group))
testX$payment = as.factor(paste(testX$payment))
testX$payment_type = as.factor(paste(testX$payment_type))
testX$water_quality = as.factor(paste(testX$water_quality))
testX$quality_group = as.factor(paste(testX$quality_group))
testX$quantity = as.factor(paste(testX$quantity))
testX$quantity_group = as.factor(paste(testX$quantity_group))
testX$source = as.factor(paste(testX$source))
testX$source_type = as.factor(paste(testX$source_type))
testX$source_class = as.factor(paste(testX$source_class))
testX$waterpoint_type = as.factor(paste(testX$waterpoint_type))
testX$waterpoint_type_group = as.factor(paste(testX$waterpoint_type_group))
testX$waterpoint_type_group
sapply(testX, class)class
sapply(testX, class)
sapply(dataset, class)
rForest = randomForest(myFormula, data = dataset, importance = TRUE, do.trace = TRUE, ntree = 1)
predVal(rForest, dataset)
pred = predict(rForest, testX)
unique(dataset$basin)
unique(testX$basin)
sum(unique(dataset$basin) == unique(testX$basin))
(unique(dataset$basin) == unique(testX$basin)
)
unique(dataset$basin)
unique(testX$basin)
unique(dataset$region)
unique(testX$region)
sort(unique(dataset$basin))
x = sort(unique(dataset$basin))
y = sort(unique(testX$basin))
sum(x == y)
x = sort(unique(dataset$region))
x = sort(unique(dataset[1]))
x = sort(unique(dataset[, 1]))
y = sort(unique(testX[1]))
sum(x == y)
x = sort(unique(dataset[, 1]))
y = sort(unique(testX[, 1]))
x = sort(unique(dataset[, 1]))
y = sort(unique(testX[, 1]))
x = sort(unique(dataset$region))
y = sort(unique(testX$region))
sum(x == y)
unique(dataset$region)
x = sort(unique(dataset$district_code))
y = sort(unique(testX$district_code))
sum(x == y)
unique(dataset$district_code)
unique(testX$district_code)
x = sort(unique(dataset$scheme_management))
y = sort(unique(testX$scheme_management))
sum(x == y)
unique(dataset$scheme_management)
unique(testX$scheme_management)
x = sort(unique(dataset$extraction_type_group))
y = sort(unique(testX$extraction_type_group))
sum(x == y)
unique(dataset$extraction_type_group)
unique(testX$extraction_type_group)
x = sort(unique(dataset$extraction_type_class))
x = sort(unique(dataset$extraction_type_class))
x = sort(unique(dataset$extraction_type_class))
y = sort(unique(testX$extraction_type_class))
sum(x == y)
unique(dataset$extraction_type_class)
unique(testX$extraction_type_group)
unique(testX$extraction_type_class)
x = sort(unique(dataset$management))
y = sort(unique(testX$management))
sum(x == y)
unique(dataset$management)
unique(testX$management)
x = sort(unique(dataset$management_group))
y = sort(unique(testX$management_group))
sum(x == y)
unique(dataset$management_group)
unique(testX$management_group)
x = sort(unique(dataset$payment))
y = sort(unique(testX$payment))
sum(x == y)
unique(dataset$payment)
unique(testX$payment)
x == y
x = sort(unique(dataset$payment_type))
y = sort(unique(testX$payment_type))
x == y
x = sort(unique(dataset$water_quality))
y = sort(unique(testX$water_quality))
x == y
x = sort(unique(dataset$quality_group))
y = sort(unique(testX$quality_group))
x == y
x = sort(unique(dataset$quantity))
y = sort(unique(testX$quantity))
x == y
x = sort(unique(dataset$quantity_group))
y = sort(unique(testX$quantity_group))
x == y
x = sort(unique(dataset$source))
y = sort(unique(testX$source))
x == y
x = sort(unique(dataset$source_type))
y = sort(unique(testX$source_type))
x == y
x = sort(unique(dataset$source_class))
y = sort(unique(testX$source_class))
x == y
x = sort(unique(dataset$waterpoint_type))
y = sort(unique(testX$waterpoint_type))
x == y
x = sort(unique(dataset$waterpoint_type_group))
y = sort(unique(testX$waterpoint_type_group))
x == y
x = sort(unique(dataset$basin))
y = sort(unique(testX$basin))
x == y
x = sort(unique(dataset$region))
y = sort(unique(testX$region))
x == y
x = sort(unique(dataset$scheme_management))
y = sort(unique(testX$scheme_management))
x == y
x = sort(unique(dataset$scheme_management))
y = sort(unique(testX$scheme_management))
x == y
unique(dataset$scheme_management)
unique(testX$scheme_management)
dataset$scheme_management = NULL
testX$scheme_management = NULL
myFormula = dataset$status_group ~ .
library(randomForest)
rForest = randomForest(myFormula, data = dataset, importance = TRUE, do.trace = TRUE, ntree = 1)
predVal(rForest, dataset)
pred = predict(rForest, testX)
rForest = randomForest(myFormula, data = dataset, importance = TRUE, do.trace = TRUE, ntree = 15)
predVal(rForest, dataset)
pred = predict(rForest, testX)
rForest = randomForest(myFormula, data = dataset, importance = TRUE, do.trace = TRUE, ntree = 90)
predVal(rForest, dataset)
pred = predict(rForest, testX)
View(pred)
library(readr)
SubmissionFormat <- read_csv("~/Documents/OneDrive/Acadêmico/ESPM/Semestre V/Tel 03.3009 - Machine Learning e Analytics/Trabalhos/taarifaProblem/data/SubmissionFormat.csv")
View(SubmissionFormat)
Final = cbind(c(SubmissionFormat, pred))
View(Final)
View(Final)
rm(Final)
View(pred)
pred2 = data.frame(pred)
View(pred)
View(pred2)
Final = cbind(c(SubmissionFormat, pred2))
View(Final)
write.csv(pred, file='output.csv')
typeof(pred)
typeof(pred2)
pred2 = data.frame(pred2)
pred2
typeof(pred2)
df = data.frame(matrix(unlist(pred2), nrow(length(pred2)), byrow=T))
df = data.frame(matrix(unlist(pred2), nrow(length(pred2)))
)
df = data.frame(matrix(unlist(pred2)))
View(df)
Final = cbind(c(SubmissionFormat, df))
View(Final)
Final
rm(df)
df = data.frame(matrix(unlist(pred2)))
df
length(pred)
length(SubmissionFormat)
nrow(SubmissionFormat)
typeof(df)
rm(df)
rm(Final)
library(readr)
trainX = read_csv("~/Documents/OneDrive/Acadêmico/ESPM/Semestre V/Tel 03.3009 - Machine Learning e Analytics/Trabalhos/taarifaProblem/data/trainX.csv")
trainX$id = NULL
trainY = read_csv("~/Documents/OneDrive/Acadêmico/ESPM/Semestre V/Tel 03.3009 - Machine Learning e Analytics/Trabalhos/taarifaProblem/data/trainY.csv")
trainY$id = NULL
dataset = cbind(trainX, trainY)
rm(trainX)
rm(trainY)
